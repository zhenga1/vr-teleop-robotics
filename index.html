<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="color-scheme" content="dark light">
  <title>Remote Teleoperation Data Collection | UR7e Ã— Meta Quest 3</title>
  <meta name="description" content="VR-based teleoperation for UR7e to collect real-world manipulation demonstrations, record trajectories, replay motion, and condition behavior using vision." />

  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;600&display=swap" rel="stylesheet">

  <style>
    :root{
      /* Base colors */
      --bg: #f8fafc;
      --surface: rgba(255,255,255,0.75);
      --surface-strong: rgba(255,255,255,0.92);
      --text: #0f172a;
      --muted: #475569;
      --muted2: #64748b;

      /* Brand */
      --brand: #6366f1;
      --brand-soft: #eef2ff;
      --accent: #22d3ee;

      /* Semantic */
      --ok: #16a34a;
      --warn: #f59e0b;
      --bad: #dc2626;

      /* Gradients */
      --g-main: linear-gradient(135deg, #6366f1, #22d3ee);
      --g-soft: linear-gradient(135deg, #eef2ff, #f8fafc);

      /* Borders & shadows */
      --stroke: rgba(15,23,42,0.08);
      --shadow-sm: 0 8px 24px rgba(15,23,42,0.06);
      --shadow-md: 0 18px 50px rgba(15,23,42,0.10);
      --shadow-lg: 0 30px 80px rgba(15,23,42,0.14);

      /* Radius */
      --r-sm: 12px;
      --r: 16px;
      --r-lg: 22px;

      /* Layout */
      --max: 1120px;
    }

    *{ box-sizing: border-box; }
    html, body{ height: 100%; }
    body {
      margin: 0;
      font-family: Inter, system-ui, sans-serif;
      color: var(--text);
      background: #f8fafc;
    }



    a{ color: inherit; text-decoration: none; }
    a:hover{ text-decoration: underline; text-decoration-color: rgba(100,100,100,0.35); }
    .wrap{ width: min(var(--max), calc(100% - 40px)); margin: 0 auto; }

    /* Top nav */
    .nav{
      position: sticky;
      top: 0;
      z-index: 50;
      backdrop-filter: blur(16px);
      background: rgba(11,15,20,0.55);
      border-bottom: 1px solid rgba(255,255,255,0.08);
    }
    .nav-inner{
      display:flex; align-items:center; justify-content:space-between;
      padding: 14px 0;
    }
    .brand{
      display:flex; align-items:center; gap:12px;
      font-weight: 700; letter-spacing: -0.02em;
    }
    .mark{
      width: 34px; height: 34px; border-radius: 12px;
      background:
        radial-gradient(14px 14px at 30% 30%, rgba(106,228,255,0.9), transparent 60%),
        radial-gradient(18px 18px at 70% 60%, rgba(167,139,250,0.85), transparent 60%),
        linear-gradient(135deg, rgba(255,255,255,0.08), rgba(255,255,255,0.02));
      border: 1px solid rgba(255,255,255,0.18);
      box-shadow: 0 12px 40px rgba(0,0,0,0.35);
    }
    .nav-links{ display:flex; gap: 16px; align-items:center; }
    .nav-links a{
      font-size: 14px;
      padding: 8px 10px;
      color: white;
      border-radius: 12px;
      border: 1px solid transparent;
    }
    .nav-links a:hover{
      color: var(--text);
      border-color: rgba(255,255,255,0.10);
      background: rgba(255,255,255,0.04);
      text-decoration: none;
    }
    .cta{
      display:flex; gap:10px; align-items:center;
    }
    .btn {
      background: white;
      border: 1px solid var(--stroke);
      color: var(--text) !important;
    }

    .btn.primary{
      color: white;
      border: none;
      background: var(--g1);
      box-shadow: 0 20px 40px rgba(99,102,241,0.35);
    }

    .btn.primary:hover{
      transform: translateY(-1px);
      box-shadow: 0 28px 60px rgba(99,102,241,0.45);
    }
    .btn .dot{
      width: 8px; height: 8px; border-radius: 50%;
      background: var(--brand);
      box-shadow: 0 0 0 6px rgba(106,228,255,0.12);
    }

    /* Hero */
    header.hero{
      padding: 58px 0 26px;
    }
    .hero-grid{
      display:grid;
      grid-template-columns: 1.25fr 0.75fr;
      gap: 22px;
      align-items: stretch;
    }
    @media (max-width: 920px){
      .hero-grid{ grid-template-columns: 1fr; }
    }
    .card {
      background: linear-gradient(
        180deg,
        rgba(255,255,255,0.04),
        rgba(255,255,255,0.01)
      );
      border: 1px solid rgba(255,255,255,0.08);
      border-radius: 16px;
      padding: 24px;
      box-shadow: 0 20px 50px rgba(0,0,0,0.5);
    }

    .hero-card{
      padding: 28px 26px;
      position: relative;
      min-height: 340px;
    }
    .hero-card::before{
      content:"";
      position:absolute;
      inset:-3px;
      background:
        radial-gradient(600px 260px at 20% 20%, rgba(99,102,241,0.35), transparent 60%),
        radial-gradient(600px 260px at 80% 30%, rgba(34,211,238,0.30), transparent 60%),
        radial-gradient(500px 240px at 50% 90%, rgba(167,139,250,0.25), transparent 60%);
      z-index: 0;
      pointer-events:none;
    }

    .hero-card > *{ position: relative; z-index: 1; }
    .kicker{
      display:flex; gap:10px; flex-wrap:wrap;
      margin-bottom: 12px;
    }
    .pill{
      font-family: var(--mono);
      font-size: 12px;
      color: rgba(10,10,10,0.90);
      padding: 7px 10px;
      border-radius: 999px;
      border: 1px solid rgba(255,255,255,0.14);
      background: rgba(255,255,255,0.04);
    }
    .pill.ok{ border-color: rgba(52,211,153,0.28); background: rgba(52,211,153,0.08); }
    .pill.b{ border-color: rgba(106,228,255,0.25); background: rgba(106,228,255,0.07); }
    .pill.p{ border-color: rgba(167,139,250,0.25); background: rgba(167,139,250,0.07); }

    h1{
      margin: 10px 0 10px;
      font-size: clamp(30px, 4.2vw, 46px);
      line-height: 1.05;
      letter-spacing: -0.04em;
    }
    .sub{
      font-size: 16px;
      line-height: 1.55;
      color: var(--muted);
      max-width: 62ch;
      margin: 0 0 18px;
    }
    .hero-actions{
      display:flex; gap: 12px; flex-wrap:wrap;
      margin-top: 14px;
    }
    .meta{
      margin-top: 18px;
      display:flex; flex-wrap:wrap;
      gap: 10px 16px;
      color: var(--muted2);
      font-size: 13px;
    }
    .meta b{ color: rgba(49, 44, 44, 0.808); font-weight: 600; }

    /* Right rail */
    .side{
      padding: 18px;
      display:flex;
      flex-direction: column;
      gap: 12px;
      min-height: 340px;
    }
    .stat{
      border-radius: var(--r);
      border: 1px solid rgba(255,255,255,0.10);
      background: rgba(255,255,255,0.03);
      padding: 14px;
    }
    .stat .label{ font-size: 12px; color: var(--muted2); font-family: var(--mono); }
    .stat .value{ margin-top: 6px; font-size: 15px; color: var(--text); font-weight: 600; }
    .stat .hint{ margin-top: 6px; font-size: 13px; color: var(--muted); line-height: 1.45; }

    /* Sections */
    section{ padding: 26px 0; }
    .section-title{
      display:flex; align-items: baseline; justify-content: space-between;
      gap: 14px;
      margin-bottom: 14px;
    }
    h2{
      margin: 0;
      font-size: 22px;
      letter-spacing: -0.02em;
    }
    .section-title p{
      margin: 0;
      color: var(--muted2);
      font-size: 13px;
      font-family: var(--mono);
    }

    .grid-3{
      display:grid;
      grid-template-columns: repeat(3, 1fr);
      gap: 14px;
    }
    @media (max-width: 980px){
      .grid-3{ grid-template-columns: 1fr; }
    }

    .panel{
      border-radius: var(--r2);
      border: 1px solid rgba(255,255,255,0.10);
      background: rgba(255,255,255,0.03);
      padding: 18px;
      box-shadow: 0 18px 60px rgba(0,0,0,0.30);
    }
    .panel h3{
      margin: 0 0 8px;
      font-size: 16px;
      letter-spacing: -0.02em;
    }
    .panel p{
      margin: 0;
      color: var(--muted);
      line-height: 1.55;
      font-size: 14px;
    }

    /* Pipeline / diagram-ish */
    .pipeline{
      display:grid;
      grid-template-columns: 1fr;
      gap: 14px;
      border: none !important;
    }
    .flow{
      display:grid;
      grid-template-columns: repeat(4, 1fr);
      gap: 12px;
      align-items: stretch;
    }
    @media (max-width: 980px){
      .flow{ grid-template-columns: 1fr; }
    }
    .node{
      border-radius: var(--r2);
      border: 1px solid rgba(0,0,0,0.8);
      background: linear-gradient(180deg, rgba(255,255,255,0.05), rgba(255,255,255,0.02));
      padding: 16px;
      position: relative;
      overflow:hidden;
    }
    .node::before{
      content:"";
      position:absolute; inset:-2px;
      background: radial-gradient(300px 120px at 30% 20%, rgba(106,228,255,0.10), transparent 60%);
      pointer-events:none;
    }
    .node:nth-child(2)::before{ background: radial-gradient(300px 120px at 30% 20%, rgba(167,139,250,0.10), transparent 60%); }
    .node:nth-child(3)::before{ background: radial-gradient(300px 120px at 30% 20%, rgba(52,211,153,0.08), transparent 60%); }
    .node:nth-child(4)::before{ background: radial-gradient(300px 120px at 30% 20%, rgba(251,191,36,0.08), transparent 60%); }
    .node > *{ position:relative; z-index:1; }
    .node .tag{
      font-family: var(--mono);
      font-size: 24px;
      color: rgba(10,0,255,0.75);
      opacity: 0.95;
    }
    .node .title{
      margin-top: 8px;
      font-weight: 700;
      letter-spacing: -0.02em;
    }
    .node ul{
      margin: 10px 0 0;
      padding-left: 18px;
      color: var(--muted);
      font-size: 13px;
      line-height: 1.55;
    }

    /* Demo gallery */
    .demo-grid{
      display:grid;
      grid-template-columns: 1.2fr 0.8fr;
      gap: 14px;
      align-items: stretch;
    }
    @media (max-width: 980px){
      .demo-grid{ grid-template-columns: 1fr; }
    }
    .demo-stage{
      border-radius: var(--r2);
      border: 1px solid rgba(255,255,255,0.10);
      background: rgba(255,255,255,0.6);
      padding: 22px;                        /* ðŸ‘ˆ more breathing room */
      box-shadow: 0 16px 40px rgba(2,6,23,0.12);
      display:flex;
      flex-direction: column;
      gap: 16px;
    }

    .media{
      border-radius: 18px;
      border: 1px dashed rgba(255,255,255,0.18);
      background:
        linear-gradient(135deg, rgba(255,255,255,0.06), rgba(255,255,255,0.02));
      min-height: 320px;
      display:grid;
      place-items: center;
      text-align:center;
      padding: 18px;
      position: relative;
      overflow:hidden;
    }
    .media::after{
      content:"";
      position:absolute; inset:-2px;
      background:
        radial-gradient(420px 220px at 25% 35%, rgba(106,228,255,0.10), transparent 60%),
        radial-gradient(420px 220px at 78% 60%, rgba(167,139,250,0.08), transparent 60%);
      pointer-events:none;
    }
    .media .ph{
      position:relative; z-index:1;
      max-width: 56ch;
    }
    .media .ph .t{
      font-weight: 700;
      letter-spacing: -0.02em;
      margin-bottom: 6px;
    }
    .media .ph .d{
      color: var(--muted);
      font-size: 14px;
      line-height: 1.55;
    }

    .demo-list{
      border-radius: var(--r2);
      border: 1px solid rgba(255,255,255,0.10);
      background: rgba(255,255,255,0.03);
      padding: 14px;
      box-shadow: 0 18px 60px rgba(0,0,0,0.28);
      display:flex;
      flex-direction: column;
      gap: 10px;
    }
    .demo-item{
      border-radius: 16px;
      border: 1px solid rgba(255,255,255,0.10);
      background: rgba(255,255,255,0.02);
      padding: 12px;
      cursor: pointer;
      transition: transform .15s ease, background .15s ease, border-color .15s ease;
    }
    .demo-item:hover{
      transform: translateY(-1px);
      border-color: rgba(106,228,255,0.18);
      background: rgba(255,255,255,0.04);
    }
    .demo-item .k{
      font-family: var(--mono);
      font-size: 12px;
      color: var(--muted2);
      margin-bottom: 6px;
    }
    .demo-item .n{
      font-weight: 700;
      letter-spacing: -0.01em;
      margin-bottom: 6px;
    }
    .demo-item .s{
      color: var(--muted);
      font-size: 13px;
      line-height: 1.45;
    }

    /* Footer */
    footer{
      padding: 26px 0 40px;
      color: var(--muted2);
      font-size: 13px;
    }
    .foot{
      display:flex; justify-content: space-between; gap: 12px; flex-wrap:wrap;
      border-top: 1px solid rgba(255,255,255,0.10);
      padding-top: 16px;
    }

    /* Modal */
    .modal{
      position: fixed; inset: 0;
      display:none;
      place-items: center;
      background: rgba(0,0,0,0.65);
      z-index: 100;
      padding: 22px;
    }
    .modal.open{ display:grid; }
    .modal-card{
      width: min(920px, 100%);
      border-radius: 22px;
      border: 1px solid rgba(255,255,255,0.14);
      background: rgba(14,18,24,0.92);
      box-shadow: 0 30px 120px rgba(0,0,0,0.70);
      overflow:hidden;
    }
    .modal-top{
      padding: 14px 16px;
      display:flex; justify-content: space-between; align-items:center;
      border-bottom: 1px solid rgba(255,255,255,0.10);
    }
    .modal-top .title{
      font-weight: 700;
      letter-spacing: -0.02em;
    }
    .modal-body{ padding: 16px; }
    .modal-body .frame{
      min-height: 420px;
      border-radius: 16px;
      border: 1px dashed rgba(255,255,255,0.18);
      background: rgba(255,255,255,0.03);
      display:grid;
      place-items:center;
      padding: 18px;
      text-align:center;
      color: var(--muted);
      line-height: 1.6;
    }
    .x{
      appearance:none;
      border: 1px solid rgba(255,255,255,0.14);
      background: rgba(255,255,255,0.05);
      color: var(--text);
      padding: 8px 10px;
      border-radius: 12px;
      cursor:pointer;
    }
    .x:hover{ background: rgba(255,255,255,0.07); }
    .vr-icon-img {
      width: 34px;
      height: 34px;
      padding: 6px;
      border-radius: 12px;
      background: rgba(255,255,255,0.06);
      border: 1px solid rgba(255,255,255,0.18);
      box-shadow: 0 10px 30px rgba(0,0,0,0.4);
    }
    .hidden {
      display: none;
    }

    #video-container {
      margin-top: 16px;
    }

    #demo-video {
      width: 420px;      /* ðŸ‘ˆ small */
      max-width: 100%;
      border-radius: 12px;
      box-shadow: 0 10px 30px rgba(0,0,0,0.25);
    }


  </style>
</head>

<body>
  <!-- NAV -->
  <div class="nav">
    <div class="wrap nav-inner">
      <div class="brand" aria-label="Project brand">
        <img src="assets/Quest-3-front-sensor-suite.png" class="vr-icon-img" alt="VR controller">
        <!--<img src="assets/quest3_right.png" class="vr-icon-img" alt="VR controller">-->
        <!-- <div class="mark" aria-hidden="true"></div> --->

        <div>
          <div style="color:white; font-size:14px; opacity:.95;">Remote Teleoperation</div>
          <div style="color: white; font-size:12px; margin-top:2px;">UR7e Ã— Meta Quest 3 â€¢ Data Collection</div>
        </div>
      </div>

      <nav class="nav-links" aria-label="Primary">
        <a href="#overview">Overview</a>
        <a href="#pipeline">Pipeline</a>
        <a href="#demos">Demos</a>
        <a href="#results">Challenges</a>
        <a href="#future">Future</a>
      </nav>

      <div class="cta">
        <a class="btn" href="#demos" title="Jump to demos">
          <span class="dot" aria-hidden="true"></span> View demos
        </a>
        <a class="btn primary" href="#contact" title="Contact / repo links">
          <span style="color: white; font-family:var(--mono); font-size:12px;">â†—</span> 
          <b style="color: white; font-family:var(--mono);">Get code</b>
        </a>
      </div>
    </div>
  </div>

  <!-- HERO -->
  <header class="hero">
    <div class="wrap hero-grid">
      <div class="card hero-card">
        <div class="kicker">
          <span class="pill b">VR teleop</span>
          <span class="pill p">trajectory logs</span>
          <span class="pill ok">replay on hardware</span>
          <span class="pill">vision-conditioned</span>
        </div>

        <h1>VR Teleoperation for Robot Data Collection & Demonstrations</h1>
        <p class="sub">
          We collect real-world robot demonstrations/trajectories on a UR7e using Meta Quest 3 controllers,
          store demonstrations in readable logs, and replay motion with conditional execution based on sensory input.
        </p>

        <div class="meta">
          <div><b>Platform:</b> UR7e</div>
          <div><b>Interface:</b> Meta Quest 3 (SteamVR/ALVR)</div>
          <div><b>Stack:</b> ROS 2 + MoveIt</div>
          <div><b>Outputs:</b> .txt logs (+ dataset placeholders)</div>
        </div>
      </div>

      <aside class="card side">
        <div class="stat">
          <div class="label">Project goal</div>
          <div class="value">Reliable remote data collection for robot learning</div>
          <div class="hint">Demonstrations/trajectories are recorded during teleoperation and replayed for training and evaluation.</div>
        </div>
        <div class="stat">
          <div class="label">Recording rate</div>
          <div class="value">2 Hz sampling (0.5 s)</div>
          <div class="hint">Aligned recording and replay for smoother execution.</div>
        </div>
        <div class="stat">
          <div class="label">Conditional execution</div>
          <div class="value">Color-based sorting â†’ replay</div>
          <div class="hint">Vision module selects which trajectory to execute based on color of objects detected.</div>
        </div>
      </aside>
    </div>
  </header>

  <!-- OVERVIEW -->
  <!-- <section id="overview">
    <div class="wrap">
      <div class="section-title">
        <h2>Overview</h2>
        <p>what & why</p>
      </div>

      <div class="grid-3">
        <div class="panel">
          <h3>Why data collection matters</h3>
          <p>
            Modern robot learning methods are data-hungryâ€”policy quality depends strongly on the diversity and fidelity
            of real-world demonstrations.
          </p>
        </div>
        <div class="panel">
          <h3>Our contribution</h3>
          <p>
            An intuitive VR teleoperation workflow using Meta Quest 3 controllers to collect UR7e manipulation trajectories,
            stored as readable logs for replay and dataset building.
          </p>
        </div>
        <div class="panel">
          <h3>Key capabilities</h3>
          <p>
            (1) VR-based 6-DoF control, (2) high-fidelity recording & storage, (3) trajectory replay on hardware,
            (4) vision-conditioned selection/sorting.
          </p>
        </div>
      </div>
    </div>
  </section> -->
  <section id="overview">
    <div class="wrap">
      <div class="section-title">
        <h2>Introduction</h2>
        <p>Goal, Motivation & Applications</p>
      </div>

      <div style="display: flex; flex-direction: column; gap: 24px;">

        <div class="panel">
          <h3 style="color: var(--brand);">Project Goal</h3>
          <p>
            Modern robot learning policies (including imitation learning and diffusion models) are constrained by a scarcity of diverse, high-quality training data, particularly for 7-DoF manipulation tasks. To address this, we developed a novel, low-cost teleoperation interface that combined Meta Quest 3 Virtual Reality headset with the UR7e robotic arm allowing a human operator to perform manipulation tasks naturally in 3D space through a headset while recording synchronized joint and gripper data to train modern Imitation Learning policies.
          </p>
        </div>

        <div class="panel">
          <h3 style="color: var(--accent);">Motivation & Technical Challenges</h3>
          <p>
            Modern robot learning (e.g., Diffusion Policies, Open X-Embodiment) is bottlenecked by the lack of high-quality demonstration data. Traditional collection methods such as kinesthetic teaching or "puppet" arms are either dangerous, unintuitive, expensive, or produce noisy and inconsistent results for complex tasks.
          </p>
          <p style="margin-top: 14px;">
            <strong>The Core Problem:</strong> This project bridges two distinct coordinate systems: the unconstrained Euclidean space of a VR controller and the kinematic constraints of an industrial robot. The key technical challenge was developing a <strong>"Logical Home Pairing" algorithm</strong> (Absolute Pose Mapping) to translate user hand poses into safe and accurate robot trajectories in real-time without risking singularities or sudden jumps.
          </p>
        </div>

        <div class="panel">
          <h3 style="color: var(--ok);">Real-World Applications</h3>
          <p>
            Beyond collecting training data for AI, this teleoperation architecture has immediate utility in several high-impact domains:
          </p>
          <ul style="margin: 12px 0 0; padding-left: 20px; color: var(--muted); font-size: 14px; line-height: 1.6;">
            <li style="margin-bottom: 6px;">
              <strong>Data Collection:</strong> Enabling scalable data generation for Open X-Embodiment initiatives.
            </li>
            <li style="margin-bottom: 6px;">
              <strong>Hazardous Environments:</strong> Allowing humans to handle toxic materials or nuclear waste from a safe distance using natural hand motions.
            </li>
            <li style="margin-bottom: 6px;">
              <strong>Remote Maintenance:</strong> Enabling technicians to repair machinery in cleanrooms or offshore rigs via VR digital twins.
            </li>
            <li>
              <strong>Space Robotics:</strong> Facilitating control of orbital manipulators where traditional joystick interfaces are too abstract for complex dexterity tasks.
            </li>
          </ul>
        </div>

      </div>
    </div>
  </section>

  <!-- PIPELINE  Maybe cahnge name to system-->
  <!-- <section id="pipeline">
    <div class="wrap">
      <div class="section-title">
        <h2>System Pipeline</h2>
        <p>inputs â†’ processing â†’ outputs</p>
      </div>

      <div class="pipeline">
        <div class="flow">
          <div class="node">
            <div class="tag">Planning / Control</div>
            <div class="title">VR Teleoperation</div>
            <ul>
              <li>Meta Quest 3 headset + controllers</li>
              <li>Coordinate mapping + pose transforms</li>
              <li>Inverse kinematics for UR7e end-effector targets</li>
            </ul>
          </div>
          <div class="node">
            <div class="tag">Data Collection</div>
            <div class="title">Record & Store</div>
            <ul>
              <li>Start/stop recording via ROS 2 services</li>
              <li>Sample joint state + gripper state</li>
              <li>Write readable <span style="font-family:var(--mono)">.txt</span> logs (dataset placeholders)</li>
            </ul>
          </div>
          <div class="node">
            <div class="tag">Actuation</div>
            <div class="title">Trajectory Replay</div>
            <ul>
              <li>Load recorded logs</li>
              <li>Timing alignment for smooth replay</li>
              <li>Execute on physical UR7e</li>
            </ul>
          </div>
          <div class="node">
            <div class="tag">Sensing</div>
            <div class="title">Vision-Based Selection</div>
            <ul>
              <li>Detect scene state (e.g., color labels)</li>
              <li>Populate job queue</li>
              <li>Replay selected trajectory conditionally</li>
            </ul>
          </div>
        </div>

        <div class="panel">
          <h3>Recorder lifecycle (editable)</h3>
          <p>
            <span style="font-family:var(--mono)">1)</span> launch recorder node â†’
            <span style="font-family:var(--mono)">2)</span> call <span style="font-family:var(--mono)">/start_recording</span> â†’
            <span style="font-family:var(--mono)">3)</span> teleoperate (timer sampling) â†’
            <span style="font-family:var(--mono)">4)</span> call <span style="font-family:var(--mono)">/stop_recording</span> to save joint + gripper states.
            <br><br>
            <span style="color:var(--muted2)">ros2 run planning teleo_recorder: Run teleo recorder</span>
            <br>
            <span style="color:var(--muted2)">ros2 run planning quest_teleop: Run teleop pipeline with Quest3</span>
            <br>
            <span style="color:var(--muted2)">ros2 run planning full_execute: Run replay with Quest3</span>
          </p>
        </div>
      </div>
    </div>
  </section> -->
  
  <section id="pipeline">
    <div class="wrap">
      
      <div class="section-title" style="margin-bottom: 40px;">
        <h2>Design Strategy</h2>
        <p>Criteria, Choices & Trade-offs</p>
      </div>

      <div class="grid-3" style="margin-bottom: 60px;">
        <div class="panel">
          <h3 style="color: var(--brand);">Design Criteria</h3>
          <p>
            To act as a viable data collection platform, the system had to meet three critical performance benchmarks:
          </p>
          <ul style="margin: 10px 0 0; padding-left: 20px; font-size: 13px; color: var(--muted); line-height: 1.6;">
            <li><strong>Latency:</strong> End-to-end delay must be <100ms to prevent user motion sickness and over-correction.</li>
            <li><strong>Safety:</strong> The system must prevent "jumps" when the VR controller is first activated.</li>
            <li><strong>Fidelity:</strong> Recorded trajectories must preserve high-frequency movements and gripper actions for successful replay.</li>
          </ul>
        </div>

        <div class="panel" style="grid-column: span 2;">
          <h3 style="color: var(--accent);">Design Choices & Trade-offs</h3>
          <p>
            We prioritized spatial intuition and operator ergonomics to ensure high-quality data collection. With this in mind we implemented an <strong>Absolute Pose Mapping</strong> strategy rather than Relative Velocity Control. 
          </p>
          <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-top: 12px;">
            <div>
              <strong style="color: var(--text); font-size: 14px;">Why we chose it:</strong>
              <p style="font-size: 13px; margin-top: 4px;">
                Absolute mapping "locks" the robot's end-effector to the user's hand, enabling intuitive spatial understanding. Velocity control often suffers from drift which often makes precise stacking tasks frustrating for the user.
              </p>
            </div>
            <div>
              <strong style="color: var(--text); font-size: 14px;">The Trade-off:</strong>
              <p style="font-size: 13px; margin-top: 4px;">
                <strong>Workspace vs. Precision:</strong> By mapping 1:1, the user is physically limited by their own arm reach. We sacrificed the ability to move infinitely by resetting the controller and its pose in exchange for higher precision and safety in a fixed workspace.
              </p>
            </div>
          </div>
        </div>

        <div class="panel" style="grid-column: span 3;">
          <h3 style="color: var(--ok);">Engineering Impact</h3>
          <p>
            Our architecture moves beyond academic theory to solve the "Data Bottleneck" in industrial robotics. We prioritized portability and fault-tolerance to create a deployable solution.
          </p>
          <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-top: 12px;">
            <div>
              <strong style="color: var(--text); font-size: 14px;">Scalable Data Pipeline (Quest 3):</strong>
              <p style="font-size: 13px; margin-top: 4px;">
                We replaced capital-intensive motion capture labs (e.g., OptiTrack) with consumer inside-out tracking. This drastically reduces the "cost per datum" and allows for decentralized data collection without specialized facility infrastructure.
              </p>
            </div>
            <div>
              <strong style="color: var(--text); font-size: 14px;">Solving the "Long Tail" (Human-in-the-Loop):</strong>
              <p style="font-size: 13px; margin-top: 4px;">
                Hard-coded automation fails on edge cases. Our teleoperation stack ensures reliability by providing a remote human fallback interface, allowing operators to resolve failures in hazardous or unstructured environments without stopping the line.
              </p>
            </div>
          </div>
        </div>
      </div>


      <div class="section-title">
  <h2>Implementation</h2>
  <p>Hardware, Software & Architecture</p>
</div>

  <div style="margin-bottom: 30px;">
  <h3 style="font-size: 18px; margin-bottom: 12px;">Hardware Signal Flow</h3>
  <p style="color: var(--muted); max-width: 65ch; margin-bottom: 20px;">
    The system operates on a distributed ROS 2 network. The system employs SteamVR and ALVR for wireless VR tracking and data streaming, which is streamed to our ROS system that uses inverse kinematics to drive the robot.
  </p>


<div style="display: flex; gap: 20px; margin-bottom: 25px; flex-wrap: wrap;">
    
    <figure style="margin: 0; flex: 1; min-width: 200px;">
      <img src="./assets/Quest3 Gear.png" 
           alt="Meta Quest 3 Headset and Controllers" 
           style="width: 100%; max-width: 300px; height: auto; border-radius: 8px; border: 1px solid #e0e0e0;">
      <figcaption style="color: var(--muted); font-size: 13px; margin-top: 8px;">
        <strong>Fig 3a:</strong> The teleoperation input device (Meta Quest 3).
      </figcaption>
    </figure>

    <figure style="margin: 0; flex: 1; min-width: 200px;">
      <img src="./assets/UR7e.png" 
           alt="Universal Robots UR7e with Robotiq Gripper" 
           style="width: 100%; max-width: 300px; height: auto; border-radius: 8px; border: 1px solid #e0e0e0;">
      <figcaption style="color: var(--muted); font-size: 13px; margin-top: 8px;">
        <strong>Fig 3b:</strong> The actuation hardware (UR7e).
      </figcaption>
    </figure>

  </div>

    
  <div style="display: flex; align-items: center; gap: 8px; flex-wrap: wrap;">
    <span class="pill p">Meta Quest 3</span>
    <span style="color: var(--muted); font-size: 18px;">â†’</span>
    
    <span class="pill">ALVR (Wireless)</span>
    <span style="color: var(--muted); font-size: 18px;">â†’</span>
    
    <span class="pill">SteamVR / OpenVR</span>
    <span style="color: var(--muted); font-size: 18px;">â†’</span>

    <span class="pill">Linux Workstation</span>
    <span style="color: var(--muted); font-size: 18px;">â†’</span>
    
    <span class="pill b">UR7e Manipulator</span>
    <span style="color: var(--muted); font-size: 18px;">â†’</span>
    
    <span class="pill">Robotiq 2F-85 (End Effector)</span>

  </div>
</div>

<div style="margin-bottom: 40px;">
  <h3 style="font-size: 18px; margin-bottom: 16px;">Software Architecture</h3>

  <div class="pipeline">
    <div class="flow">
      <div class="node">
        <div class="tag">Input</div>
        <div class="title">VR Teleop Node</div>
        <ul>
          <li><strong>Bridge:</strong> ALVR Server &harr; Client</li>
          <li><strong>Source:</strong> SteamVR/OpenVR Poses</li>
        </ul>
      </div>
      
      <div class="node">
        <div class="tag">Process</div>
        <div class="title">Recorder Node</div>
        <ul>
          <li>Syncs Joint States + Gripper</li>
          <li><strong>Service:</strong> <code>/start_recording</code></li>
        </ul>
      </div>

      <div class="node">
        <div class="tag">Output</div>
        <div class="title">Serialization</div>
        <ul>
          <li><strong>.npz:</strong> Compressed (Training)</li>
          <li><strong>.txt:</strong> Human-Readable (Debug)</li>
          <li><strong>Service:</strong> <code>/stop_recording</code></li>
        </ul>
      </div>

      <div class="node">
        <div class="tag">Actuation</div>
        <div class="title">Replay Node</div>
        <ul>
          <li>Parses .npz logs</li>
          <li>Interpolates Trajectory</li>
          <li>Publishes to UR Controller</li>
        </ul>
      </div>
    </div>
  </div>
</div>

  <div style="margin-top: 60px;">

  <div class="panel" style="margin-bottom: 30px;">
    <h3 style="color: var(--brand); border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 15px;">
      1. Real-Time SE(3) Teleoperation Controller
    </h3>
    <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 30px;">
      
      <div>
        <p style="font-size: 14px; color: var(--muted); margin-bottom: 15px;">
          The system implements a <strong>72Hz synchronous control loop</strong>. To ensure intuitive handling, we decouple the absolute coordinate systems using a "Logical Home" calibration. This allows the operator to map a comfortable hand position ($\mathbf{P}_{vr}$) to the robot's safety home ($\mathbf{P}_{robot}$) instantly.
        </p>
        <div style="background: #f8f9fa; padding: 12px; border-radius: 6px; border-left: 3px solid var(--brand);">
          <strong style="font-size: 12px; color: #333;">Control Law:</strong>
          <p style="font-family: 'Times New Roman', serif; font-size: 15px; margin: 5px 0 0 0;">
             T<sub>target</sub> = (T<sub>robot_home</sub> &cdot; T<sub>vr_home</sub><sup>-1</sup>) &cdot; T<sub>vr_live</sub>(t)
          </p>
        </div>
      </div>

      <div style="background: #1e1e1e; border-radius: 6px; padding: 12px; overflow-x: auto; display: flex; flex-direction: column; justify-content: center;">
        <div style="color: #6A9955; font-family: monospace; font-size: 11px; margin-bottom: 4px;"># Calculate Offset Matrix</div>
        <pre style="margin: 0; font-family: 'Courier New', monospace; font-size: 11px; color: #d4d4d4; line-height: 1.4;">
# 1. Capture current transforms
T_robot = tf_buffer.lookup('base', 'wrist_3')
T_vr    = openvr.get_pose('controller')

# 2. Compute alignment offset
self.T_offset = T_robot @ np.linalg.inv(T_vr)
self.calibrated = True</pre>
      </div>
    </div>
  </div>

  <div class="panel" style="margin-bottom: 30px;">
    <h3 style="color: var(--accent); border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 15px;">
      2. Trajectory Logging & State Serialization
    </h3>
    <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 30px;">
      
      <div>
        <p style="font-size: 14px; color: var(--muted); margin-bottom: 15px;">
          To support Imitation Learning, mere position logging is insufficient. We implement a <strong>RAM-buffered recorder</strong> that captures the full kinematic state vector at 30Hz. Data is serialized into compressed NumPy archives (<code>.npz</code>) to preserve floating-point precision for model training.
        </p>
        <div style="display: flex; gap: 8px; flex-wrap: wrap;">
           <span class="pill" style="font-size: 11px; background: #eee; color: #555;">t (timestamp)</span>
           <span class="pill" style="font-size: 11px; background: #eee; color: #555;">q (joint_pos &#x211D;<sup>6</sup>)</span>
           <span class="pill" style="font-size: 11px; background: #eee; color: #555;">gripper (bool)</span>
        </div>
      </div>

      <div style="background: #1e1e1e; border-radius: 6px; padding: 12px; overflow-x: auto; display: flex; flex-direction: column; justify-content: center;">
        <div style="color: #6A9955; font-family: monospace; font-size: 11px; margin-bottom: 4px;"># Flush buffer to disk</div>
        <pre style="margin: 0; font-family: 'Courier New', monospace; font-size: 11px; color: #d4d4d4; line-height: 1.4;">
def save_trajectory(self):
    # Normalize time t0 -> 0
    t = self.t_log - self.t_log[0]
    
    # Save compressed for Training
    np.savez_compressed(f"demo_{timestamp}.npz", 
        t=t, q=self.q_log, gripper=self.g_log)</pre>
      </div>
    </div>
  </div>

  <div class="panel" style="margin-bottom: 60px;"> <h3 style="color: var(--ok); border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 15px;">
      3. Vision-Gated Replay (Perception Loop)
    </h3>
    <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 30px;">
      
      <div>
        <p style="font-size: 14px; color: var(--muted); margin-bottom: 15px;">
          For autonomous playback, we utilize a <strong>Depth-Gated HSV Filter</strong>. This filters out background noise by ensuring candidate objects lie within the table's specific Z-plane (0.75m â€“ 1.1m). Once a valid target is confirmed, the system triggers a Cubic Spline interpolation of the recorded trajectory.
        </p>
        <ul style="font-size: 13px; color: var(--muted); padding-left: 20px; margin: 0;">
          <li><strong>Blue:</strong> HSV[95-130] + Depth[0.75m]</li>
          <li><strong>Green:</strong> HSV[60-100] + Depth[0.75m]</li>
        </ul>
      </div>

      <div style="background: #1e1e1e; border-radius: 6px; padding: 12px; overflow-x: auto; display: flex; flex-direction: column; justify-content: center;">
        <div style="color: #6A9955; font-family: monospace; font-size: 11px; margin-bottom: 4px;"># Depth-Gated Color Detection</div>
        <pre style="margin: 0; font-family: 'Courier New', monospace; font-size: 11px; color: #d4d4d4; line-height: 1.4;">
# 1. Spatial Filter (Z-Gate)
depth_m = depth_frame[cy, cx] * scale
if not (0.75 < depth_m < 1.1):
    return # Ignore background noise

# 2. Spectral Filter (HSV)
if cv2.inRange(hsv, blue_lo, blue_hi).any():
    trigger_replay("blue_path")</pre>
      </div>
    </div>
  </div>

</div> <div class="panel" style="margin-top: 40px; margin-bottom: 80px;">
  <h3 style="color: var(--text); border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 15px;">
    (d) System Operation Workflow
  </h3>
  <ol style="margin: 0; padding-left: 20px; color: var(--muted); line-height: 1.8; font-size: 14px;">
    <li style="margin-bottom: 8px;">
      <strong>Initialization:</strong> Launch SteamVR and the ALVR Server on the workstation. Open the ALVR Client on the Quest 3 to establish the wireless handshake.
    </li>
    <li style="margin-bottom: 8px;">
      <strong>Calibration:</strong> Position the robot in "Home" state. Hold the VR controller in a neutral pose and trigger the <strong>Grip</strong> button to calculate the local T<sub>offset</sub> matrix.
    </li>
    <li style="margin-bottom: 8px;">
      <strong>Data Collection:</strong> Press <strong>Button A</strong> to trigger the <code>/start_recording</code> service. Perform the manipulation task.
    </li>
    <li>
      <strong>Serialization:</strong> Press <strong>Button B</strong> to trigger <code>/stop_recording</code>, which flushes the RAM buffer to a timestamped <code>.npz</code> file.
    </li>
  </ol>
</div>


<div style="border-top: 1px solid #e0e0e0; margin-bottom: 60px;"></div>


<div class="wrap" style="margin-bottom: 60px;">
  
  <div class="section-title" style="margin-bottom: 40px;">
    <h2>System Pipeline Recap</h2>
    <p>End-to-End Data Flow Summary</p>
  </div>

  <div class="pipeline">
    <div class="flow">
      <div class="node">
        <div class="tag">Planning</div>
        <div class="title">VR Teleoperation</div>
        <ul>
          <li>Meta Quest 3 (Input)</li>
          <li>Coordinate Mapping</li>
          <li>Inverse Kinematics</li>
        </ul>
      </div>
      <div class="node">
        <div class="tag">Collection</div>
        <div class="title">Record & Store</div>
        <ul>
          <li>ROS 2 Services</li>
          <li>Joint State Sampling</li>
          <li>.npz Serialization</li>
        </ul>
      </div>
      <div class="node">
        <div class="tag">Actuation</div>
        <div class="title">Trajectory Replay</div>
        <ul>
          <li>Load Logs</li>
          <li>Spline Interpolation</li>
          <li>Execute on UR7e</li>
        </ul>
      </div>
      <div class="node">
        <div class="tag">Sensing</div>
        <div class="title">Vision Selection</div>
        <ul>
          <li>HSV Color Detect</li>
          <li>Job Queueing</li>
          <li>Conditional Replay</li>
        </ul>
      </div>
    </div>
  </div>

  <div class="panel" style="margin-top: 30px; background: #f8f9fa; border: 1px solid #e0e0e0;">
    <h3 style="font-size: 14px; text-transform: uppercase; color: #888; margin-bottom: 10px;">Recorder Lifecycle</h3>
    <p style="font-family: monospace; font-size: 13px; color: #555;">
      1) Launch Node &rarr; 2) /start_recording &rarr; 3) Teleoperate &rarr; 4) /stop_recording
    </p>
  </div>

</div>
  </section>

  <!-- DEMOS -->
  <section id="demos">
    <div class="wrap">
      <div class="section-title">
        <h2>Demos</h2>
        <!-- <p>placeholders (drop-in videos/gifs)</p> -->
      </div>

      <div class="demo-grid">
        <!-- LEFT: Full pipeline demo -->
        <div class="demo-stage">
          <div class="media hero-video">
            <div class="video-container">
              <iframe
                src="https://drive.google.com/file/d/1eMcpyJhRtLM1I6wXNmuv1Oq4-d7S8RSg/preview"
                width="420"
                height="236"
                allow="autoplay"
                style="border-radius:12px; border:none;">
              </iframe>
            </div>
            

            <div class="caption">
              End-to-end VR teleoperation â†’ recording â†’ vision â†’ replay on UR7e
            </div>
          </div>
        </div>

        <!-- RIGHT: Teleop + Replay -->
        <div class="demo-stage">
          <div class="media small-video">
            <div class="video-container">
              <iframe
                src="https://drive.google.com/file/d/1cHVPyW85sx2RR0owW8st4kCQn0yvuLPx/preview"
                width="420"
                height="236"
                allow="autoplay"
                style="border-radius:12px; border:none;">
              </iframe>
            </div>
            <div class="caption">VR Teleoperation</div>
          </div>

          <div class="media small-video">
            <div class="video-container">
              <iframe
                src="https://drive.google.com/file/d/1W1PUVvYM2rJ6aDVlx4ujo7Q-EyYwW9Er/preview"
                width="420"
                height="236"
                allow="autoplay"
                style="border-radius:12px; border:none;">
              </iframe>
            </div>
            <div class="caption">Trajectory Replay</div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- CHALLENGES / RESULTS -->
  <section id="results">
    <div class="wrap">
      <div class="section-title">
        <h2>Challenges & Engineering Notes</h2>
        <p>what broke, what we fixed</p>
      </div>

      <div class="grid-3">
        <div class="panel">
          <h3>Hardware / networking</h3>
          <p>
            Getting the Quest headset + controllers reliably connected on the same local network as the lab computer.
            <!-- <br><br><span style="color:var(--muted2)">Placeholder: add your final network topology + troubleshooting steps.</span> -->
          </p>
        </div>
        <div class="panel">
          <h3>Software / timing alignment</h3>
          <p>
            Smooth trajectory replay requires consistent timing between recorded samples and playback speed.
            <!-- <br><br><span style="color:var(--muted2)">Placeholder: add your exact interpolation / rate-control strategy.</span> -->
          </p>
        </div>
        <div class="panel">
          <h3>Reliability / safety</h3>
          <p>
            Bounding box constraints, speed limiting, and per-joint control can reduce noise and improve safety.
            <!-- <br><br><span style="color:var(--muted2)">Placeholder: add safety checks you implemented in ROS nodes.</span> -->
          </p>
        </div>
      </div>
    </div>
  </section>

  <!-- FUTURE -->
  <section id="future">
    <div class="wrap">
      <div class="section-title">
        <h2>Future Considerations</h2>
        <p>next iterations</p>
      </div>

      <div class="grid-4">
        <div class="panel">
          <h3>Controls</h3>
          <p>
            PID per joint, velocity limiting, and filtering to reduce noise and improve stability during teleop and replay.
          </p>
        </div>
        <div class="panel">
          <h3>Safety bounding</h3>
          <p>
            Add robot workspace bounding and proximity checks to prevent unsafe motions near lab fixtures and people.
          </p>
        </div>
        <div class="panel">
          <h3>Dataset packaging</h3>
          <p>
            Export trajectories to a consistent schema (e.g., timestamps + joints + gripper + camera metadata) and release a small benchmark set.
          </p>
        </div>
        <div class="panel">
          <h3>Reinforcement Learning</h3>
          <p>
            Incorporate reinforcement learning to build upon the teleoperated demonstrations collected in this project. Rather than relying on task-specific object placement, learned policies will adapt the demonstrated trajectories to new object poses and environmental variations, improving robustness and generalization.
          </p>
        </div>
      </div>
    </div>
  </section>

<section id="team" style="margin-top: 80px; margin-bottom: 80px;">
  
  <div style="max-width: 1100px; margin: 0 auto; padding: 0 20px;">

    <div class="section-title" style="border-top: 1px solid #eee; padding-top: 40px; margin-bottom: 30px;">
      <h2>4. Project Team</h2>
      <p>Roles & Contributions</p>
    </div>

    <div style="display: flex; flex-direction: column; gap: 20px;">

      <div class="panel" style="display: flex; flex-wrap: wrap; gap: 30px; align-items: start;">
        <div style="flex: 0 0 220px; min-width: 200px;">
          <h3 style="color: var(--brand); margin-bottom: 5px; font-size: 18px;">Samuel Mankoff</h3>
          <span style="font-size: 11px; text-transform: uppercase; letter-spacing: 0.5px; color: #999; display: block; line-height: 1.4;">
            Masterâ€™s Student<br>Mechanical Engineering
          </span>
        </div>
        <div style="flex: 1; min-width: 280px;">
          <p style="font-size: 14px; color: var(--muted); margin-bottom: 12px;">
            Interested in robotic control, perception, and learning. Focused on designing robots that can replicate human manipulation skills.
          </p>
          <div style="padding-top: 10px; border-top: 1px solid #f0f0f0;">
            <strong style="font-size: 12px; color: #333;">Key Contribution:</strong>
            <span style="font-size: 13px; color: var(--muted);">
              Led development of the VR-based teleoperation pipeline (Quest 3). Assisted with robot control logic and trajectory mapping.
            </span>
          </div>
        </div>
      </div>

      <div class="panel" style="display: flex; flex-wrap: wrap; gap: 30px; align-items: start;">
        <div style="flex: 0 0 220px; min-width: 200px;">
          <h3 style="color: var(--brand); margin-bottom: 5px; font-size: 18px;">Akshaj Gupta</h3>
          <span style="font-size: 11px; text-transform: uppercase; letter-spacing: 0.5px; color: #999; display: block; line-height: 1.4;">
            Sophomore<br>EECS
          </span>
        </div>
        <div style="flex: 1; min-width: 280px;">
          <p style="font-size: 14px; color: var(--muted); margin-bottom: 12px;">
            Interested in working with robotic manipulators and exploring the intersection of robotics and music applications.
          </p>
          <div style="padding-top: 10px; border-top: 1px solid #f0f0f0;">
            <strong style="font-size: 12px; color: #333;">Key Contribution:</strong>
            <span style="font-size: 13px; color: var(--muted);">
              Developed the Computer Vision Pipeline (HSV/Depth) and implemented the trajectory saving/replay logic.
            </span>
          </div>
        </div>
      </div>

      <div class="panel" style="display: flex; flex-wrap: wrap; gap: 30px; align-items: start;">
        <div style="flex: 0 0 220px; min-width: 200px;">
          <h3 style="color: var(--brand); margin-bottom: 5px; font-size: 18px;">Kourosh Salahi</h3>
          <span style="font-size: 11px; text-transform: uppercase; letter-spacing: 0.5px; color: #999; display: block; line-height: 1.4;">
            Junior<br>EECS & Business
          </span>
        </div>
        <div style="flex: 1; min-width: 280px;">
          <p style="font-size: 14px; color: var(--muted); margin-bottom: 12px;">
            Focused on machine learning applications for robotics, specifically control strategies for humanoid platforms.
          </p>
          <div style="padding-top: 10px; border-top: 1px solid #f0f0f0;">
            <strong style="font-size: 12px; color: #333;">Key Contribution:</strong>
            <span style="font-size: 13px; color: var(--muted);">
              Contributed to the CV sensing pipeline for object detection and performed data collection trials via teleoperation.
            </span>
          </div>
        </div>
      </div>


    <div class="panel" style="display: flex; flex-wrap: wrap; gap: 30px; align-items: start;">
        <div style="flex: 0 0 220px; min-width: 200px;">
          <h3 style="color: var(--brand); margin-bottom: 5px; font-size: 18px;">Ziteng (Ender) Ji</h3>
          <span style="font-size: 11px; text-transform: uppercase; letter-spacing: 0.5px; color: #999; display: block; line-height: 1.4;">
            Senior<br>Computer Science
          </span>
        </div>
        <div style="flex: 1; min-width: 280px;">
          <p style="font-size: 14px; color: var(--muted); margin-bottom: 12px;">
            Research interests lie in robot learning, specifically enabling robots to acquire sophisticated skills through data-driven approaches.
          </p>
          <div style="padding-top: 10px; border-top: 1px solid #f0f0f0;">
            <strong style="font-size: 12px; color: #333;">Key Contribution:</strong>
            <span style="font-size: 13px; color: var(--muted);">
              Architected the Meta Quest connection with UR7e and assisted in the physical setup of the teleoperation workspace.
            </span>
          </div>
        </div>
      </div>

      <div class="panel" style="display: flex; flex-wrap: wrap; gap: 30px; align-items: start;">
        <div style="flex: 0 0 220px; min-width: 200px;">
          <h3 style="color: var(--brand); margin-bottom: 5px; font-size: 18px;">Aaron Zheng</h3>
          <span style="font-size: 11px; text-transform: uppercase; letter-spacing: 0.5px; color: #999; display: block; line-height: 1.4;">
            Senior<br>EECS
          </span>
        </div>
        <div style="flex: 1; min-width: 280px;">
          <p style="font-size: 14px; color: var(--muted); margin-bottom: 12px;">
            Interested in humanoid robots and LLMs. Focusing on learning-based policies for motion execution in simulation.
          </p>
          <div style="padding-top: 10px; border-top: 1px solid #f0f0f0;">
            <strong style="font-size: 12px; color: #333;">Key Contribution:</strong>
            <span style="font-size: 13px; color: var(--muted);">
              Assisted with the Meta Quest to UR7e network bridge and teleoperation testing.
            </span>
          </div>
        </div>
      </div>

    </div>
  </div>
</section>
  <!-- TEAM / CONTACT -->
  <section id="contact">
    <div class="wrap">
      <div class="section-title">
        <h2>Links</h2>
        <p>placeholders</p>
      </div>

      <div class="grid-3">
        <div class="panel">
          <h3>Team</h3>
          <p>
            B.S.: Aaron Zheng, Akshaj Gupta, Kourosh Salahi, Ziteng (Ender) Ji<br>
            M.S.: Samuel Mankoff
          </p>
        </div>
        <div class="panel">
          <h3>Repository</h3>
          <p>
            <span style="color:var(--muted2)">Link:</span><br>
            <span style="font-family:var(--mono); font-size:12px;">
              <a href="https://github.com/samuel-mankoff/meceng206a-Final-Project" target="_blank" style="color:inherit; text-decoration:underline;">
                https://github.com/samuel-mankoff/meceng206a-Final-Project
              </a>
            </span>
          </p>
        </div>
        <div class="panel">
          <h3>Demo assets</h3>
          <p>
            <span style="color:var(--muted2)">Placeholder:</span> add Google Drive / YouTube / local files<br>
            Suggested: <span style="font-family:var(--mono)">/assets/demo_01.webm</span>, <span style="font-family:var(--mono)">/assets/teaser.gif</span>
          </p>
        </div>
      </div>
    </div>
  </section>

  <footer>
    <div class="wrap foot">
      <div> <span id="year" style="font-family:var(--mono); font-size: 16px;"></span> Remote Teleoperation Data Collection â€¢ ME206A Project Group 18</div>
      <div style="display:flex; gap:14px; flex-wrap:wrap;">
        <a href="#overview">Overview</a>
        <a href="#pipeline">Pipeline</a>
        <a href="#demos">Demos</a>
        <a href="#contact">Contact</a>
      </div>
    </div>
  </footer>

  <!-- MODAL -->
  <div class="modal" id="modal" role="dialog" aria-modal="true" aria-label="Demo modal">
    <div class="modal-card">
      <div class="modal-top">
        <div class="title" id="modalTitle">Demo</div>
        <button class="x" id="closeModal" aria-label="Close">âœ•</button>
      </div>
      <div class="modal-body">
        <div class="frame" id="modalFrame">
          <div>
            <div style="font-weight:700; color: rgba(255,255,255,0.86); margin-bottom:8px;">Placeholder</div>
            Drop your embedded video here (YouTube iframe / local WebM / GIF).<br>
            You can also show a ROS graph, RViz screenshot, or a short â€œterminal + robotâ€ montage.
          </div>
        </div>
        <div style="margin-top:10px; color:var(--muted2); font-size:12px; font-family:var(--mono);">
          Tip: Keep each clip â‰¤ 20 seconds; add one end-to-end cut as the hero demo.
        </div>
      </div>
    </div>
  </div>

  <script>
    // Smooth scroll helpers
    document.querySelectorAll("[data-scroll]").forEach(btn => {
      btn.addEventListener("click", () => {
        const sel = btn.getAttribute("data-scroll");
        const el = document.querySelector(sel);
        if (el) el.scrollIntoView({ behavior: "smooth", block: "start" });
      });
    });

    // Demo modal behavior
    const modal = document.getElementById("modal");
    const modalTitle = document.getElementById("modalTitle");
    const modalFrame = document.getElementById("modalFrame");
    const closeModal = document.getElementById("closeModal");

    const demoMeta = {
      vr: {
        title: "DEMO 01 â€¢ VR Control",
        hint: "Replace with a video showing controller motion, IK targets, and UR7e following smoothly."
      },
      record: {
        title: "DEMO 02 â€¢ Recording",
        hint: "Replace with: service call start/stop + a quick peek at saved .txt trajectory."
      },
      replay: {
        title: "DEMO 03 â€¢ Replay",
        hint: "Replace with a replay clip; consider side-by-side with the original teleop."
      },
      vision: {
        title: "DEMO 04 â€¢ Vision-conditioned Selection",
        hint: "Replace with camera overlay + detected label â†’ job queue â†’ chosen trajectory."
      },
      full: {
        title: "DEMO 05 â€¢ End-to-end",
        hint: "Replace with your best final showcase montage for a recruiter-friendly overview."
      }
    };

    document.querySelectorAll(".demo-item").forEach(item => {
      item.addEventListener("click", () => {
        const key = item.getAttribute("data-demo");
        const meta = demoMeta[key] || { title: "Demo", hint: "Placeholder" };
        modalTitle.textContent = meta.title;
        modalFrame.innerHTML = `
          <div>
            <div style="font-weight:700; color: rgba(255,255,255,0.86); margin-bottom:8px;">${meta.title}</div>
            <div style="max-width:62ch;">
              ${meta.hint}<br><br>
              <span style="opacity:.9;">Drop-in options:</span>
              <ul style="text-align:left; margin:10px auto 0; width:min(560px, 100%); color: rgba(255,255,255,0.72); line-height:1.6;">
                <li>Local WebM: &lt;video src="assets/demo_${key}.webm" controls&gt;&lt;/video&gt;</li>
                <li>YouTube: iframe embed</li>
                <li>GIF: &lt;img src="assets/demo_${key}.gif"&gt;</li>
              </ul>
            </div>
          </div>
        `;
        modal.classList.add("open");
      });
    });

    function close() { modal.classList.remove("open"); }
    closeModal.addEventListener("click", close);
    modal.addEventListener("click", (e) => { if (e.target === modal) close(); });
    window.addEventListener("keydown", (e) => { if (e.key === "Escape") close(); });

    // Footer year
    document.getElementById("year").textContent = new Date().getFullYear();
  </script>
</body>
</html>
